{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from PIL import Image\n",
    "from skimage import color, filters\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "import urllib.request\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = ['go', 'stop', 'warning']\n",
    "color_map = {'go':'green', 'stop':'red', 'warning':'yellow'}\n",
    "rgb_color_map = {'go': (0, 255, 0), 'stop': (255, 0, 0), 'warning': (255, 255, 0)}\n",
    "\n",
    "train_folder_list = [\n",
    "    'dayTrain',\n",
    "#     'daySequence1',\n",
    "#     'daySequence2',\n",
    "#     'sample-dayClip6',\n",
    "    'nightTrain',\n",
    "#     'nightSequence1',\n",
    "#     'nightSequence2',\n",
    "#     'sample-nightClip1',\n",
    "]\n",
    "\n",
    "n_samples_per_class = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotarion_dataframe(train_data_folders):\n",
    "    data_base_path = '../input/lisa-traffic-light-dataset/'\n",
    "    annotation_list = list()\n",
    "    for folder in [folder + '/' for folder in train_data_folders if os.listdir(data_base_path)]:\n",
    "        annotation_path = ''\n",
    "        if 'sample' not in folder:\n",
    "            annotation_path = data_base_path + 'Annotations/Annotations/' + folder\n",
    "        else:\n",
    "            annotation_path = data_base_path + folder*2\n",
    "        image_frame_path = data_base_path + folder*2\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        if 'Clip' in os.listdir(annotation_path)[0]:\n",
    "            clip_list = os.listdir(annotation_path)\n",
    "            for clip_folder in clip_list:\n",
    "                df = pd.read_csv(annotation_path + clip_folder +  '/frameAnnotationsBOX.csv', sep=\";\")\n",
    "                df['image_path'] = image_frame_path + clip_folder + '/frames/'\n",
    "                annotation_list.append(df)\n",
    "        else:\n",
    "            df = pd.read_csv(annotation_path +  'frameAnnotationsBOX.csv', sep=\";\")\n",
    "            df['image_path'] = image_frame_path + 'frames/'\n",
    "            annotation_list.append(df)\n",
    "        \n",
    "    df = pd.concat(annotation_list)\n",
    "    df = df.drop(['Origin file', 'Origin frame number', 'Origin track', 'Origin track frame number'], axis=1)\n",
    "    df.columns = ['filename', 'target', 'x1', 'y1', 'x2', 'y2', 'image_path']\n",
    "    df = df[df['target'].isin(target_classes)]\n",
    "    df['filename'] = df['filename'].apply(lambda filename: re.findall(\"\\/([\\d\\w-]*.jpg)\", filename)[0])\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dayClip1--00000.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>698</td>\n",
       "      <td>333</td>\n",
       "      <td>710</td>\n",
       "      <td>358</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/dayTrain/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dayClip1--00000.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>846</td>\n",
       "      <td>391</td>\n",
       "      <td>858</td>\n",
       "      <td>411</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/dayTrain/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dayClip1--00001.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>698</td>\n",
       "      <td>337</td>\n",
       "      <td>710</td>\n",
       "      <td>357</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/dayTrain/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dayClip1--00001.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>847</td>\n",
       "      <td>390</td>\n",
       "      <td>859</td>\n",
       "      <td>410</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/dayTrain/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dayClip1--00002.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>698</td>\n",
       "      <td>331</td>\n",
       "      <td>710</td>\n",
       "      <td>356</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/dayTrain/d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42565</th>\n",
       "      <td>nightClip5--01450.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>937</td>\n",
       "      <td>221</td>\n",
       "      <td>976</td>\n",
       "      <td>290</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/nightTrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42566</th>\n",
       "      <td>nightClip5--01451.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>467</td>\n",
       "      <td>36</td>\n",
       "      <td>512</td>\n",
       "      <td>117</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/nightTrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42567</th>\n",
       "      <td>nightClip5--01451.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>937</td>\n",
       "      <td>219</td>\n",
       "      <td>976</td>\n",
       "      <td>288</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/nightTrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42568</th>\n",
       "      <td>nightClip5--01452.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>460</td>\n",
       "      <td>33</td>\n",
       "      <td>506</td>\n",
       "      <td>114</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/nightTrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42569</th>\n",
       "      <td>nightClip5--01452.jpg</td>\n",
       "      <td>go</td>\n",
       "      <td>937</td>\n",
       "      <td>219</td>\n",
       "      <td>976</td>\n",
       "      <td>288</td>\n",
       "      <td>../input/lisa-traffic-light-dataset/nightTrain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42570 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename target   x1   y1   x2   y2  \\\n",
       "0        dayClip1--00000.jpg     go  698  333  710  358   \n",
       "1        dayClip1--00000.jpg     go  846  391  858  411   \n",
       "2        dayClip1--00001.jpg     go  698  337  710  357   \n",
       "3        dayClip1--00001.jpg     go  847  390  859  410   \n",
       "4        dayClip1--00002.jpg     go  698  331  710  356   \n",
       "...                      ...    ...  ...  ...  ...  ...   \n",
       "42565  nightClip5--01450.jpg     go  937  221  976  290   \n",
       "42566  nightClip5--01451.jpg     go  467   36  512  117   \n",
       "42567  nightClip5--01451.jpg     go  937  219  976  288   \n",
       "42568  nightClip5--01452.jpg     go  460   33  506  114   \n",
       "42569  nightClip5--01452.jpg     go  937  219  976  288   \n",
       "\n",
       "                                              image_path  \n",
       "0      ../input/lisa-traffic-light-dataset/dayTrain/d...  \n",
       "1      ../input/lisa-traffic-light-dataset/dayTrain/d...  \n",
       "2      ../input/lisa-traffic-light-dataset/dayTrain/d...  \n",
       "3      ../input/lisa-traffic-light-dataset/dayTrain/d...  \n",
       "4      ../input/lisa-traffic-light-dataset/dayTrain/d...  \n",
       "...                                                  ...  \n",
       "42565  ../input/lisa-traffic-light-dataset/nightTrain...  \n",
       "42566  ../input/lisa-traffic-light-dataset/nightTrain...  \n",
       "42567  ../input/lisa-traffic-light-dataset/nightTrain...  \n",
       "42568  ../input/lisa-traffic-light-dataset/nightTrain...  \n",
       "42569  ../input/lisa-traffic-light-dataset/nightTrain...  \n",
       "\n",
       "[42570 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotation_df = get_annotarion_dataframe(train_folder_list)\n",
    "\n",
    "target_classes = train_annotation_df['target'].unique()\n",
    "target_classes.sort()\n",
    "\n",
    "train_annotation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, x1, y1, x2, y2):\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "    cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bouding_boxes(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Convert the image array to L*a*b* color space\n",
    "    lab_image = color.rgb2lab(image_array)\n",
    "\n",
    "    # Extract the L, a, and b channels\n",
    "    L = lab_image[:, :, 0]\n",
    "    a = lab_image[:, :, 1]\n",
    "    b = lab_image[:, :, 2]\n",
    "\n",
    "\n",
    "    # Calculate the RGYB channel\n",
    "    RGYB = 0.7*L * (1.0*a + 0.7*b)\n",
    "    YELLOW = 0.7*L * (0.7*a + b)\n",
    "\n",
    "\n",
    "    # Create a mask for red and green blobs\n",
    "    red_mask = np.logical_and(RGYB > 2000, L <= 80)\n",
    "    green_mask = np.logical_and(RGYB < -2000, L <= 80)\n",
    "    yellow_mask = np.logical_and(YELLOW > 1000, RGYB <= 2000)\n",
    "\n",
    "    # Apply the masks to the original image\n",
    "    red_blobs = np.zeros_like(image_array)\n",
    "    red_blobs[red_mask] = image_array[red_mask]\n",
    "    green_blobs = np.zeros_like(image_array)\n",
    "    green_blobs[green_mask] = image_array[green_mask]\n",
    "    yellow_blobs = np.zeros_like(image_array)\n",
    "    yellow_blobs[yellow_mask] = image_array[yellow_mask]\n",
    "\n",
    "    # Convert the red and green blobs to grayscale\n",
    "    red_gray = color.rgb2gray(red_blobs)\n",
    "    green_gray = color.rgb2gray(green_blobs)\n",
    "    yellow_gray = color.rgb2gray(yellow_blobs)\n",
    "\n",
    "    red_gray = np.where(red_gray > 0, 255, 0).astype(np.uint8)\n",
    "    green_gray = np.where(green_gray > 0, 255, 0).astype(np.uint8)\n",
    "    yellow_gray = np.where(yellow_gray > 0, 255, 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "    # Use built-in sobel filter in hough circle transform.\n",
    "    red_edges = red_gray\n",
    "    green_edges = green_gray\n",
    "    yellow_edges = yellow_gray\n",
    "\n",
    "    # Perform Hough circle detection on red edges\n",
    "    red_radii = np.arange(5, 30)  # Define the expected radius range for red circles\n",
    "    red_hough = hough_circle(red_edges, red_radii)\n",
    "    red_accums, red_centers_x, red_centers_y, red_radii = hough_circle_peaks(red_hough, red_radii, threshold=0.90*np.max(red_hough), min_xdistance = 50, min_ydistance = 50)\n",
    "\n",
    "    # Perform Hough circle detection on green edges\n",
    "    green_radii = np.arange(5, 30)  # Define the expected radius range for red circles\n",
    "    green_hough = hough_circle(green_edges, green_radii)\n",
    "    green_accums, green_centers_x, green_centers_y, green_radii = hough_circle_peaks(green_hough, green_radii, threshold=0.90*np.max(green_hough), min_xdistance=50, min_ydistance = 50)\n",
    "\n",
    "    # Perform Hough circle detection on yellow edges\n",
    "    yellow_radii = np.arange(5, 30)  # Define the expected radius range for yellow circles\n",
    "    yellow_hough = hough_circle(yellow_edges, yellow_radii)\n",
    "    yellow_accums, yellow_centers_x, yellow_centers_y, yellow_radii = hough_circle_peaks(yellow_hough, yellow_radii, threshold=0.90*np.max(yellow_hough), min_xdistance=50, min_ydistance = 50)\n",
    "\n",
    "    # Draw detected circles on the original image\n",
    "\n",
    "    cropped_images = []\n",
    "    bounding_boxes = []\n",
    "    labels = []\n",
    "\n",
    "    red_circles_image = np.copy(image_array)\n",
    "    for center_y, center_x, radius in zip(red_centers_y, red_centers_x, red_radii):\n",
    "        circy, circx = circle_perimeter(center_y, center_x, radius)\n",
    "        valid_coords = np.logical_and(circy >= 0, circy < red_circles_image.shape[0]) & np.logical_and(circx >= 0, circx < red_circles_image.shape[1])\n",
    "        red_circles_image[circy[valid_coords], circx[valid_coords]] = (0, 255, 0)  # Red color for circles\n",
    "        max_x = red_circles_image.shape[1]\n",
    "        max_y = red_circles_image.shape[0]\n",
    "        x1, y1, x2, y2 = max(0,center_x - 1.9*radius), max(0, center_y - 1.9*radius), min(max_x, center_x + 1.9*radius), min(max_y, center_y + (7.0)*radius)\n",
    "        x1, x2, y1, y2 = round(x1), round(x2), round(y1), round(y2) \n",
    "        cropped_images.append(crop_image(image_array, x1, y1, x2, y2))\n",
    "        bounding_boxes.append([x1, y1, x2, y2])\n",
    "        labels.append(\"red\")\n",
    "\n",
    "\n",
    "    green_circles_image = np.copy(image_array)\n",
    "    for center_y, center_x, radius in zip(green_centers_y, green_centers_x, green_radii):\n",
    "        circy, circx = circle_perimeter(center_y, center_x, radius)\n",
    "        valid_coords = np.logical_and(circy >= 0, circy < green_circles_image.shape[0]) & np.logical_and(circx >= 0, circx < green_circles_image.shape[1])\n",
    "        green_circles_image[circy[valid_coords], circx[valid_coords]] = (255, 0, 0)  # Green color for circles\n",
    "        max_x = green_circles_image.shape[1]\n",
    "        max_y = green_circles_image.shape[0]\n",
    "        x1, y1, x2, y2 = max(0,center_x - 1.9*radius), max(0, center_y - 7.0*radius), min(max_x, center_x + 1.9*radius), min(max_y, center_y + (1.9)*radius)\n",
    "        x1, x2, y1, y2 = round(x1), round(x2), round(y1), round(y2) \n",
    "        cropped_images.append(crop_image(image_array, x1, y1, x2, y2))\n",
    "        bounding_boxes.append([x1, y1, x2, y2])\n",
    "        labels.append(\"green\")\n",
    "        \n",
    "    yellow_circles_image = np.copy(image_array)\n",
    "    for center_y, center_x, radius in zip(yellow_centers_y, yellow_centers_x, yellow_radii):\n",
    "        circy, circx = circle_perimeter(center_y, center_x, radius)\n",
    "        valid_coords = np.logical_and(circy >= 0, circy < yellow_circles_image.shape[0]) & np.logical_and(circx >= 0, circx < yellow_circles_image.shape[1])\n",
    "        yellow_circles_image[circy[valid_coords], circx[valid_coords]] = (0, 0, 255)  # yellow color for circles\n",
    "        max_x = yellow_circles_image.shape[1]\n",
    "        max_y = yellow_circles_image.shape[0]\n",
    "        x1, y1, x2, y2 = max(0,center_x - 1.9*radius), max(0, center_y - 4.1*radius), min(max_x, center_x + 1.0*radius), min(max_y, center_y + (4.1)*radius)\n",
    "        x1, x2, y1, y2 = round(x1), round(x2), round(y1), round(y2) \n",
    "        cropped_images.append(crop_image(image_array, x1, y1, x2, y2))\n",
    "        bounding_boxes.append([x1, y1, x2, y2])\n",
    "        labels.append(\"yellow\") \n",
    "    return cropped_images, bounding_boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxA, boxB):\n",
    "    # Extract the coordinates of the bounding boxes\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # Calculate the intersection area\n",
    "    intersection_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # Calculate the areas of both bounding boxes\n",
    "    boxA_area = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxB_area = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # Calculate the union area\n",
    "    union_area = float(boxA_area + boxB_area - intersection_area)\n",
    "\n",
    "    # Calculate the IOU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filenames = train_annotation_df['filename'].unique()\n",
    "id_1 = 0\n",
    "id_2 = 0\n",
    "\n",
    "# Iterate over each unique filename\n",
    "for filename in unique_filenames:\n",
    "    # Filter rows with the current filename\n",
    "    random_number = np.random.rand()\n",
    "    if (random_number > 0.05):\n",
    "        continue\n",
    "\n",
    "    filtered_rows = train_annotation_df[train_annotation_df['filename'] == filename]\n",
    "    img_path = filtered_rows.iloc[0]['image_path']\n",
    "    img_name = filtered_rows.iloc[0]['filename']\n",
    "\n",
    "\n",
    "    cropped_images, bounding_boxes, labels = generate_bouding_boxes(img_path + img_name)\n",
    "    for bb_id, bb in enumerate(bounding_boxes):\n",
    "        corrected = False\n",
    "        for index, row in filtered_rows.iterrows():\n",
    "            x1 = row['x1']\n",
    "            y1 = row['y1']\n",
    "            x2 = row['x2']\n",
    "            y2 = row['y2']\n",
    "            if (calculate_iou(bb, [x1, y1, x2, y2]) > 0.3):\n",
    "                corrected = True\n",
    "\n",
    "        label = \"traffic_light\" if corrected else \"not_traffic_light\"\n",
    "        img_to_save = (cropped_images[bb_id])\n",
    "        if not corrected:\n",
    "            output_path = \"../input/\"+label+\"/\"+str(id_2)+\".jpg\"\n",
    "            cv2.imwrite(output_path, img_to_save)\n",
    "            id_2+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filenames = train_annotation_df['filename'].unique()\n",
    "random.shuffle(unique_filenames)\n",
    "\n",
    "count = {'green': 0, 'red': 0, 'yellow': 0}\n",
    "for filename in unique_filenames:\n",
    "    filtered_rows = train_annotation_df[train_annotation_df['filename'] == filename]\n",
    "    img_path = filtered_rows.iloc[0]['image_path']\n",
    "    img_name = filtered_rows.iloc[0]['filename']\n",
    "\n",
    "    n_items = 0\n",
    "\n",
    "    for index, row in filtered_rows.iterrows():\n",
    "        x1 = row['x1']\n",
    "        y1 = row['y1']\n",
    "        x2 = row['x2']\n",
    "        y2 = row['y2']\n",
    "        target = row['target']\n",
    "        target = color_map[target]\n",
    "\n",
    "        random_number = np.random.rand()\n",
    "        count[target]+= 1\n",
    "        if (count[target] > 3000):\n",
    "            continue\n",
    "\n",
    "        img = cv2.imread(img_path + img_name)\n",
    "        output_img = crop_image(img, x1, y1, x2, y2)\n",
    "        output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        output_path = \"../input/\" + target + \"/\"+str(count[target])+\".jpg\"\n",
    "        cv2.imwrite(output_path, output_img)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
